---
output:
  word_document: default
  pdf_document: default
  html_document: default
---
```{r}
library(KoNLP)
```
```{r}
library(tm)2
```
```{r}
library(wordcloud)
```
#설치시 오류가 뜬다면 경로에 한글이 포함되었는지를 확인해봅니다.
```{r}
seoul <- file("C:/Users/wonjun/Desktop/Rproject/data/2018seoul.txt")
```

```{r}
seoul_data <- readLines(seoul)
```
# 만약 incomplete final line found on 오류가 발생한다면
# txt파일에 들어가서 마지막 한줄을 띄우거나
# 다른이름으로 저장하면서 인코딩을 UTF-8로 바꾸어 줍니다.
```{r}
seoul_data2 <- sapply(seoul_data, extractNoun, USE.NAMES=F)
```
#paste(Base) : 나열된 원소 사이에 공백을 두고 결과값을 출력하는 함수입니다.
#extractNoun(KoNLP) : 명사를 추출하는 함수입니다.
#character : 문자로 형변환 해주는 함수입니다.
#collapse : paste 함수의 옵션으로 각각 적용한 결과물을 collapse 단어로 이어 붙일수 있습니다.
#sapply : 벡터,리스트,표현식,데이터 프레임 등에 함수를 적용하고 그 결과를 벡터 또는 행렬로 반환하는 함수입니다.
#lapply ; 결과를 리스트로 반환하는 함수입니다.
```{r}
head(unlist(seoul_data2),30)
```
#head : 디폴트로 앞에 값을 출력한다.
#tail : 디폴트로 뒤에 값을 출력한다.
#unlist : 리스트를 벡터로 변환하는 wj 함수이다.
```{r}
Cseoul <- VCorpus(VectorSource(seoul_data2))
```
#출현 빈도를 정리한 문서를 Term Document Matrix라고 하며 
#tm패키지에서는 Term Document Matrix를 사용하여 빈도 분석을 진행합니다.
#Term Document Matrix는 Corpus형태(말뭉치)라는 특별한 형태만 받기 때문에
#text를 일단 Corpus형태로 바꾸기 위해 Corpus(VectorSource())함수를 사용해 줍니다.
```{r}
Cseoul <- tm_map(Cseoul, removePunctuation)
```
#tm_map : 데이터를 정재해주는 함수입니다.
#removePunctuation : 구두점을 제거해주는 함수입니다.
```{r}
Cseoul <- tm_map(Cseoul, removeNumbers)
```
#removeNumbers : 숫자를 제거해주는 함수입니다.
```{r}
Cseoul <- tm_map(Cseoul, tolower)
```
#tolower : 소문자로 변환해주는 함수입니다.
```{r}
Cseoul <- tm_map(Cseoul, removeWords, stopwords('english'))
```
#stopwords : 불용어를 제거해주는 함수입니다. 추가적으로 제외하고 싶은 단어를 적어주면 됩니다.
```{r}
inspect(Cseoul[1:5])
```
#inspect : 문서 정보를 보여주는 함수입니다.
```{r}
seoul_data3 <- tm_map(Cseoul, PlainTextDocument)
```
#PlainTextDocument : 위의 전처리한 단어는 Corpus형태 이기 때문에 다시 일반문서로 변경시켜줍니다.
```{r}
library(SnowballC)
```

```{r}
seoul_data3 <- TermDocumentMatrix(seoul_data3, control=list(wordLengths=c(2,Inf)))
```
#만약 Error in simple_triplet_matrix 오류가 뜬다면 Corpus가 아닌 VCorpus를 사용하면 됩니다.
#wordLengths : 2~Inf 음절로 이루어진 단어만 추출합니다.
```{r}
seoul_df <- as.data.frame(as.matrix(seoul_data3))
```
#matrix를 data.frame으로 변경해줍니다.
```{r}
wordResult<- sort(rowSums(seoul_df),decreasing = TRUE)
```
#rowSums : 각 행의 합계로 구성된 벡터입니다.
```{r}
wordResult[1:10]
```
```{r}
myName <- names(wordResult)
```1
#names : 단어 이름을 추출합니다.
```{r}
wordcloud(myName, wordResult)
```
#분석 결과를 워드클라우드를 생성합니다.
#워드클라우드를 디자인 해보겠습니다.
```{r}
word.df<-data.frame(word=myName, freq=wordResult)
```
#단어이름과 빈도수로 data.frame을 생성합니다.
```{r}
word.df
```
```{r}
pal <- brewer.pal(12,"Paired")
```
#brewer.pal : 원하는 팔레트(Paired)에 색상(12)을 선택합니다.
```{r}
wordcloud(word.df$word, word.df$freq, scale=c(5,1),min.freq=3,random.order=F,rot.per=.1,colors=pal)
```
#scale : 폰트크기 c(MAX,MIN)
#rot.per : 회전되는 단어의 빈도 .1일때
#random.order=F : 빈도가 큰 단어를 중앙에 오도록 합니다.
#random.color=T : 실행시마다 색이 변화하도록 합니다.
